/**
 * =====================================================================
 * ADVANCED CACHING UTILITIES - T·ªëi ∆∞u h√≥a b·ªô nh·ªõ ƒë·ªám
 * =====================================================================
 *
 * üìö GI·∫¢I TH√çCH CHO TH·ª∞C T·∫¨P SINH:
 *
 * 1. UNSTABLE_CACHE (Next.js 15+):
 * - ƒê√¢y l√† API m·∫°nh m·∫Ω c·ªßa Next.js ƒë·ªÉ cache k·∫øt qu·∫£ c·ªßa c√°c h√†m b·∫•t ƒë·ªìng b·ªô (v√≠ d·ª•: g·ªçi database, g·ªçi API).
 * - Kh√°c v·ªõi fetch cache, n√≥ cho ph√©p ta g·∫Øn "tags" ƒë·ªÉ x√≥a cache m·ªôt c√°ch c√≥ ch·ªçn l·ªçc (`revalidateTag`).
 *
 * 2. C√ÅC PATTERNS CACHE PH·ªî BI·∫æN:
 * - SWR (Stale-While-Revalidate): Tr·∫£ v·ªÅ d·ªØ li·ªáu c≈© ngay l·∫≠p t·ª©c v√† √¢m th·∫ßm c·∫≠p nh·∫≠t d·ªØ li·ªáu m·ªõi ·ªü background.
 * - Multi-level: K·∫øt h·ª£p Memory cache (c·ª±c nhanh) v√† Next.js cache (b·ªÅn v·ªØng).
 * - Deduplication: N·∫øu 10 n∆°i c√πng g·ªçi 1 API t·∫°i 1 th·ªùi ƒëi·ªÉm, ch·ªâ c√≥ 1 request th·ª±c s·ª± ƒë∆∞·ª£c g·ª≠i ƒëi.
 *
 * 3. T·∫†I SAO PH·∫¢I D√ôNG?
 * - Gi·∫£m chi ph√≠ server (Database/API calls).
 * - TƒÉng t·ªëc ƒë·ªô ph·∫£n h·ªìi (TTFB) cho ng∆∞·ªùi d√πng cu·ªëi.
 * =====================================================================
 */

import { unstable_cache } from "next/cache";

/**
 * Wrapper h·ªó tr·ª£ cache h√†m v·ªõi c√°c tags ƒë·ªÉ x√≥a cache c√≥ ch·ªçn l·ªçc.
 */
export function createCachedFunction<
  T extends (...args: any[]) => Promise<any>
>(
  fn: T,
  {
    keyPrefix,
    tags = [],
    revalidate,
  }: {
    keyPrefix: string;
    tags?: string[];
    revalidate?: number | false;
  }
): T {
  return ((...args: Parameters<T>) => {
    const cacheKey = `${keyPrefix}-${JSON.stringify(args)}`;

    return unstable_cache(async () => fn(...args), [cacheKey], {
      tags: [...tags, cacheKey],
      revalidate,
    })();
  }) as T;
}

/**
 * Pattern Stale-While-Revalidate (SWR)
 * Tr·∫£ v·ªÅ d·ªØ li·ªáu c≈© ngay l·∫≠p t·ª©c v√† revalidate (c·∫≠p nh·∫≠t) ·ªü background.
 */
export function createSWRCache<T extends (...args: any[]) => Promise<any>>(
  fn: T,
  {
    keyPrefix,
    staleTime = 60, // M·∫∑c ƒë·ªãnh 1 ph√∫t (stale)
  }: {
    keyPrefix: string;
    staleTime?: number;
    // revalidateTime?: number; // Removed unused parameter
  }
): T {
  return ((...args: Parameters<T>) => {
    const cacheKey = `swr-${keyPrefix}-${JSON.stringify(args)}`;

    return unstable_cache(
      async () => {
        try {
          return await fn(...args);
        } catch (error) {
          console.error(`[SWR Cache] L·ªói cho key ${cacheKey}:`, error);
          // Return stale data on error if available
          throw error;
        }
      },
      [cacheKey],
      {
        tags: [keyPrefix, cacheKey],
        revalidate: staleTime,
      }
    )();
  }) as T;
}

/**
 * Cache v·ªõi t√≠nh nƒÉng t·ª± ƒë·ªông "l√†m n√≥ng" (warming)
 * Ch·ªß ƒë·ªông n·∫°p d·ªØ li·ªáu v√†o cache cho c√°c d·ªØ li·ªáu th∆∞·ªùng xuy√™n ƒë∆∞·ª£c truy c·∫≠p.
 */
export async function warmCache<T>(
  fn: () => Promise<T>,
  {
    key,
    tags = [],
    revalidate = 3600,
  }: {
    key: string;
    tags?: string[];
    revalidate?: number;
  }
): Promise<T> {
  const cachedFn = unstable_cache(fn, [key], {
    tags: [...tags, key],
    revalidate,
  });

  return cachedFn();
}

/**
 * C∆° ch·∫ø Cache ƒëa l·ªõp (Multi-level caching):
 * 1. Memory cache: Nhanh nh·∫•t, t·ªìn t·∫°i theo t·ª´ng request ho·∫∑c th·ªùi gian ng·∫Øn.
 * 2. Next.js cache: L∆∞u tr√™n server, b·ªÅn v·ªØng h∆°n (File-system based).
 * 3. API call: Ch·∫°y khi c·∫£ 2 l·ªõp tr√™n ƒë·ªÅu kh√¥ng c√≥ d·ªØ li·ªáu (Cache miss).
 */
const memoryCache = new Map<string, { data: any; expires: number }>();

export function createMultiLevelCache<
  T extends (...args: any[]) => Promise<any>
>(
  fn: T,
  {
    keyPrefix,
    memoryTTL = 10, // 10 seconds in memory
    cacheTTL = 60, // 60 seconds in Next.js cache
    tags = [],
  }: {
    keyPrefix: string;
    memoryTTL?: number;
    cacheTTL?: number;
    tags?: string[];
  }
): T {
  return (async (...args: Parameters<T>) => {
    const cacheKey = `${keyPrefix}-${JSON.stringify(args)}`;
    const now = Date.now();

    // L·ªõp 1: Memory cache (B·ªô nh·ªõ RAM)
    const memCached = memoryCache.get(cacheKey);
    if (memCached && memCached.expires > now) {
      return memCached.data;
    }

    // L·ªõp 2: Next.js cache (File system/Persistent)
    const cachedFn = unstable_cache(async () => fn(...args), [cacheKey], {
      tags: [...tags, cacheKey],
      revalidate: cacheTTL,
    });

    const result = await cachedFn();

    // L∆∞u v√†o memory cache ƒë·ªÉ d√πng l·∫°i c·ª±c nhanh trong request sau
    memoryCache.set(cacheKey, {
      data: result,
      expires: now + memoryTTL * 1000,
    });

    // D·ªçn d·∫πp memory cache c≈© n·∫øu v∆∞·ª£t qu√° 100 entries ƒë·ªÉ tr√°nh t·ªën RAM
    if (memoryCache.size > 100) {
      const keysToDelete: string[] = [];
      memoryCache.forEach((value, key) => {
        if (value.expires < now) {
          keysToDelete.push(key);
        }
      });
      keysToDelete.forEach((key) => memoryCache.delete(key));
    }

    return result;
  }) as T;
}

/**
 * Kh·ª≠ tr√πng l·∫∑p (Deduplication) cho c√°c request ƒë·ªìng th·ªùi.
 * N·∫øu c√≥ nhi·ªÅu request c√πng g·ªçi 1 d·ªØ li·ªáu t·∫°i 1 th·ªùi ƒëi·ªÉm -> Ch·ªâ th·ª±c hi·ªán 1 API call.
 */
const pendingRequests = new Map<string, Promise<any>>();

export function createDedupedCache<T extends (...args: any[]) => Promise<any>>(
  fn: T,
  keyPrefix: string
): T {
  return (async (...args: Parameters<T>) => {
    const cacheKey = `${keyPrefix}-${JSON.stringify(args)}`;

    // Tr·∫£ v·ªÅ request ƒëang ch·∫°y n·∫øu c√≥ (Tr√°nh g·ªçi tr√πng)
    if (pendingRequests.has(cacheKey)) {
      return pendingRequests.get(cacheKey);
    }

    // T·∫°o request m·ªõi n·∫øu ch∆∞a c√≥ c√°i n√†o ƒëang ch·∫°y
    const promise = fn(...args).finally(() => {
      pendingRequests.delete(cacheKey);
    });

    pendingRequests.set(cacheKey, promise);
    return promise;
  }) as T;
}

/**
 * Gom nh√≥m c√°c request (Batching)
 * K·∫øt h·ª£p nhi·ªÅu request l·∫ª t·∫ª v√†o th√†nh m·ªôt request duy nh·∫•t ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng.
 */
export function createBatchedCache<T>(
  fetcher: (ids: string[]) => Promise<T[]>,
  {
    maxBatchSize = 10,
    maxWaitMs = 50,
  }: {
    maxBatchSize?: number;
    maxWaitMs?: number;
  }
) {
  const batch: string[] = [];
  const resolvers: Array<(value: T | null) => void> = [];
  let timeoutId: NodeJS.Timeout | null = null;

  const executeBatch = async () => {
    if (batch.length === 0) return;

    const currentBatch = batch.splice(0);
    const currentResolvers = resolvers.splice(0);

    try {
      const results = await fetcher(currentBatch);
      const resultMap = new Map(results.map((item: any) => [item.id, item]));

      currentBatch.forEach((id, index) => {
        currentResolvers[index](resultMap.get(id) || null);
      });
    } catch (error) {
      console.error("[Batch Cache] L·ªói khi th·ª±c thi batch:", error);
      currentResolvers.forEach((resolve) => resolve(null));
    }
  };

  return async (id: string): Promise<T | null> => {
    return new Promise((resolve) => {
      batch.push(id);
      resolvers.push(resolve);

      if (batch.length >= maxBatchSize) {
        if (timeoutId) clearTimeout(timeoutId);
        executeBatch();
      } else if (!timeoutId) {
        timeoutId = setTimeout(() => {
          timeoutId = null;
          executeBatch();
        }, maxWaitMs);
      }
    });
  };
}
